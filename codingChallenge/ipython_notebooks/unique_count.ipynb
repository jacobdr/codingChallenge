{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter, OrderedDict\n",
    "from operator import itemgetter\n",
    "import tempfile\n",
    "import numpy as np\n",
    "from codingChallenge import utils\n",
    "\n",
    "\n",
    "class UniqueWordsCalculator(object):\n",
    "    \"\"\"\n",
    "    Class container for the functions related to coungint the number of unique\n",
    "    words as Tweets arrive\n",
    "    \"\"\"\n",
    "    def __init__(self, tweet_iterable, path_to_input_file):\n",
    "        self.tweet_iterable = tweet_iterable\n",
    "        self.input_file_path = path_to_input_file\n",
    "\n",
    "    def count_unique(self):\n",
    "        \"\"\"\n",
    "        This is the function documentation\n",
    "        \"\"\"\n",
    "        count_container = Counter()\n",
    "        for tweet in self.tweet_iterable:\n",
    "            # Encapsulte tweet in string call and return strip to\n",
    "            # escape any strange characters\n",
    "            count_container = count_container + \\\n",
    "                Counter(utils.clean_tweet(tweet).split(\" \"))\n",
    "\n",
    "        sorted_count_dictionary = OrderedDict(sorted(count_container.items(),\n",
    "                                              key=itemgetter(0)))\n",
    "\n",
    "        # Remove edge cases of blank string or space string\n",
    "        sorted_count_dictionary.pop(' ', None)\n",
    "        sorted_count_dictionary.pop('', None)\n",
    "        return sorted_count_dictionary\n",
    "\n",
    "    def counter_on_all_words(self):\n",
    "        with tempfile.TemporaryFile() as tmpfile:\n",
    "            # Clean each tweet and write it out to the temporary file, with\n",
    "            # a trailing newline\n",
    "            for tweet in self.tweet_iterable:\n",
    "                for word in utils.clean_tweet(tweet).split(\" \"):\n",
    "                    tmpfile.write(word + \"\\n\")\n",
    "            # Make sure that the file is at the beginning and then create a\n",
    "            # Counter from it to get the unique items\n",
    "            tmpfile.seek(0)\n",
    "            count_container = Counter(tmpfile.read().splitlines())\n",
    "\n",
    "            sorted_count_dictionary = OrderedDict(sorted(count_container.items(),\n",
    "                                              key=itemgetter(0)))\n",
    "            return sorted_count_dictionary.items()\n",
    "\n",
    "    def numpy_count_unique(self):\n",
    "        tweet_array = np.genfromtxt(self.input_file_path,dtype=np.string_, comments=False, delimiter=\"\\n\")\n",
    "        print tweet_array\n",
    "        word_array = np.concatenate([tweet.split() for tweet in tweet_array])\n",
    "        word_count = Counter(word_array)\n",
    "        alphabetized_count = OrderedDict(sorted(word_count.items(), key=itemgetter(0)))\n",
    "        return alphabetized_count.items()\n",
    "\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Create a generic run method on the object to make reimplemntation\n",
    "        easier. That way code in the Dispatcher doesn't need to be refactored\n",
    "        \"\"\"\n",
    "        # return self.count_unique()\n",
    "        return self.numpy_count_unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    test_tweets = [\n",
    "        \"is #bigdata finally the answer to end poverty? \\\n",
    "        @lavanyarathnam http://ow.ly/o8gt3 #analytics\",\n",
    "        \"interview: xia wang, astrazeneca on #bigdata and the promise of effective \\\n",
    "        healthcare #kdn http://ow.ly/ot2uj\",\n",
    "        \"big data is not just for big business. on how #bigdata is being deployed for \\\n",
    "        small businesses: http://bddy.me/1bzukb3 @cxotodayalerts #smb\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def numpy_count_unique(input_text):\n",
    "        print input_text\n",
    "        tweet_array = np.genfromtxt(input_text, comments=False, dtype=np.string_, delimiter=\"\\n\")\n",
    "        print tweet_array\n",
    "        word_array = np.concatenate([tweet.split() for tweet in tweet_array])\n",
    "        word_count = Counter(word_array)\n",
    "        alphabetized_count = OrderedDict(sorted(word_count.items(), key=itemgetter(0)))\n",
    "        return alphabetized_count.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['is #bigdata finally the answer to end poverty?     @lavanyarathnam http://ow.ly/o8gt3 #analytics', 'interview: xia wang, astrazeneca on #bigdata and the promise of effective     healthcare #kdn http://ow.ly/ot2uj', 'big data is not just for big business. on how #bigdata is being deployed for     small businesses: http://bddy.me/1bzukb3 @cxotodayalerts #smb']\n",
      "[ 'is #bigdata finally the answer to end poverty?     @lavanyarathnam http://ow.ly/o8gt3 #analytics'\n",
      " 'interview: xia wang, astrazeneca on #bigdata and the promise of effective     healthcare #kdn http://ow.ly/ot2uj'\n",
      " 'big data is not just for big business. on how #bigdata is being deployed for     small businesses: http://bddy.me/1bzukb3 @cxotodayalerts #smb']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('#analytics', 1),\n",
       " ('#bigdata', 3),\n",
       " ('#kdn', 1),\n",
       " ('#smb', 1),\n",
       " ('@cxotodayalerts', 1),\n",
       " ('@lavanyarathnam', 1),\n",
       " ('and', 1),\n",
       " ('answer', 1),\n",
       " ('astrazeneca', 1),\n",
       " ('being', 1),\n",
       " ('big', 2),\n",
       " ('business.', 1),\n",
       " ('businesses:', 1),\n",
       " ('data', 1),\n",
       " ('deployed', 1),\n",
       " ('effective', 1),\n",
       " ('end', 1),\n",
       " ('finally', 1),\n",
       " ('for', 2),\n",
       " ('healthcare', 1),\n",
       " ('how', 1),\n",
       " ('http://bddy.me/1bzukb3', 1),\n",
       " ('http://ow.ly/o8gt3', 1),\n",
       " ('http://ow.ly/ot2uj', 1),\n",
       " ('interview:', 1),\n",
       " ('is', 3),\n",
       " ('just', 1),\n",
       " ('not', 1),\n",
       " ('of', 1),\n",
       " ('on', 2),\n",
       " ('poverty?', 1),\n",
       " ('promise', 1),\n",
       " ('small', 1),\n",
       " ('the', 2),\n",
       " ('to', 1),\n",
       " ('wang,', 1),\n",
       " ('xia', 1)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_count_unique(test_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Some errors were detected !\n    Line #2 (got 5 columns instead of 1)\n    Line #3 (got 10 columns instead of 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-308-3490d7a985fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/Users/Jacob/Documents/Projects/DataInsight/codingChallenge/codingChallenge/tests/fixtures/tweet_input/tweets.txt\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtest_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtweet_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mtweet_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mword_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweet_array\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mword_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Jacob/anaconda/lib/python2.7/site-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36mgenfromtxt\u001b[0;34m(fname, dtype, comments, delimiter, skiprows, skip_header, skip_footer, converters, missing, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise)\u001b[0m\n\u001b[1;32m   1690\u001b[0m             \u001b[0;31m# Raise an exception ?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minvalid_raise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m             \u001b[0;31m# Issue a warning ?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Some errors were detected !\n    Line #2 (got 5 columns instead of 1)\n    Line #3 (got 10 columns instead of 1)"
     ]
    }
   ],
   "source": [
    "with open(\"/Users/Jacob/Documents/Projects/DataInsight/codingChallenge/codingChallenge/tests/fixtures/tweet_input/tweets.txt\") as test_file:\n",
    "    tweet_array = np.genfromtxt(test_file, dtype=np.string_, delimiter=' ')\n",
    "    print tweet_array\n",
    "    word_array = np.concatenate([tweet.split() for tweet in tweet_array])\n",
    "    word_count = Counter(word_array)\n",
    "    alphabetized_count = OrderedDict(sorted(word_count.items(), key=itemgetter(0)))\n",
    "    print alphabetized_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.genfromtxt(\"/Users/Jacob/Documents/Projects/DataInsight/codingChallenge/benchmark/data/1k_tweets.txt\",\n",
    "             dtype='|S160',\n",
    "             delimiter=\"\\n\",\n",
    "            )\n",
    "\n",
    "def split_string(in_string):\n",
    "    return in_string.split()\n",
    "vfunc = np.vectorize(split_string, otypes=[np.string_])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = Counter(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.array([['a','b','c'], ['d','e','f','g']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a', 'b', 'c'] ['d', 'e', 'f', 'g']]\n",
      "[['a', 'b', 'c'] ['d', 'e', 'f', 'g']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['a', 'b', 'c', 'd', 'e', 'f', 'g'], \n",
       "      dtype='|S1')"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print a\n",
    "print a.ravel()\n",
    "np.concatenate(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a', 'b', 'c'] ['d', 'e', 'f', 'g']]\n"
     ]
    }
   ],
   "source": [
    "print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
